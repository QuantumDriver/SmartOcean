{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 必要依赖包加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.model_selection import KFold,StratifiedKFold,train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.set_option('display.max_columns',100)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_hdf('./input/train.h5')\n",
    "test = pd.read_hdf('./input/test.h5')\n",
    "\n",
    "test['type'] = -1\n",
    "data = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征工程 <br>\n",
    "- 对速度v做出va加速度的特征来,并且把加速度的各种描述性统计特征做出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关于分位数特征\n",
    "def get_v_fea(df):\n",
    "    try1 = df\n",
    "    t = try1.groupby('ship')['v'].agg({'v_per_1':lambda x:sp.stats.mstats.hdquantiles(x,[0.1])}).reset_index()\n",
    "    try1 = pd.merge(try1, t, on='ship', how='left')\n",
    "    t = try1.groupby('ship')['v'].agg({'v_per_2':lambda x:sp.stats.mstats.hdquantiles(x,[0.2])}).reset_index()\n",
    "    try1 = pd.merge(try1, t, on='ship', how='left')\n",
    "    t = try1.groupby('ship')['v'].agg({'v_per_3':lambda x:sp.stats.mstats.hdquantiles(x,[0.3])}).reset_index()\n",
    "    try1 = pd.merge(try1, t, on='ship', how='left')\n",
    "    t = try1.groupby('ship')['v'].agg({'v_per_4':lambda x:sp.stats.mstats.hdquantiles(x,[0.4])}).reset_index()\n",
    "    try1 = pd.merge(try1, t, on='ship', how='left')\n",
    "    t = try1.groupby('ship')['v'].agg({'v_per_5':lambda x:sp.stats.mstats.hdquantiles(x,[0.5])}).reset_index()\n",
    "    try1 = pd.merge(try1, t, on='ship', how='left')\n",
    "    t = try1.groupby('ship')['v'].agg({'v_per_6':lambda x:sp.stats.mstats.hdquantiles(x,[0.6])}).reset_index()\n",
    "    try1 = pd.merge(try1, t, on='ship', how='left')\n",
    "    t = try1.groupby('ship')['v'].agg({'v_per_7':lambda x:sp.stats.mstats.hdquantiles(x,[0.7])}).reset_index()\n",
    "    try1 = pd.merge(try1, t, on='ship', how='left')\n",
    "    t = try1.groupby('ship')['v'].agg({'v_per_8':lambda x:sp.stats.mstats.hdquantiles(x,[0.8])}).reset_index()\n",
    "    try1 = pd.merge(try1, t, on='ship', how='left')\n",
    "    t = try1.groupby('ship')['v'].agg({'v_per_9':lambda x:sp.stats.mstats.hdquantiles(x,[0.9])}).reset_index()\n",
    "    try1 = pd.merge(try1, t, on='ship', how='left')\n",
    "    df = try1\n",
    "    return df\n",
    "\n",
    "def get_x_fea(df):\n",
    "    try1 = df\n",
    "    t = try1.groupby('ship')['x'].agg({'x_per_1':lambda x:sp.stats.mstats.hdquantiles(x,[0.1])}).reset_index()\n",
    "    try1 = pd.merge(try1, t, on='ship', how='left')\n",
    "    df = try1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_feature(df,key,target,aggs):\n",
    "    agg_dict = {}\n",
    "    for ag in aggs:\n",
    "        agg_dict[f'{target}_{ag}'] = ag\n",
    "    print(agg_dict)\n",
    "    # 以key进行分组,选择特定的特征提取其函数结果作为新特征,函数包含在字典中\n",
    "    t = df.groupby(key)[target].agg(agg_dict).reset_index()\n",
    "    return t\n",
    "\n",
    "def extract_feature(df,train):\n",
    "    # ship指船号,对每一艘船的x,y,v,d的数据的特征进行提取\n",
    "    t = group_feature(df, 'ship','x',['max','min','mean','std','skew','sum','count','median','mad'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','y',['max','min','mean','std','skew','sum','median','mad'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','v',['max','min','mean','std','skew','sum','median','mad'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','d',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    # 加和乘效果都不好，减和除对模型提分有帮助\n",
    "    train['x_max_x_min'] = train['x_max'] - train['x_min']\n",
    "    train['y_max_y_min'] = train['y_max'] - train['y_min']\n",
    "    train['y_max_x_min'] = train['y_max'] - train['x_min']\n",
    "    train['x_max_y_min'] = train['x_max'] - train['y_min']\n",
    "\n",
    "    train['x_max_over_x_min'] = train['x_max'] / train['x_min']\n",
    "    train['y_max_over_y_min'] = train['y_max'] / train['y_min']\n",
    "    train['y_max_over_x_min'] = train['y_max'] / train['x_min']\n",
    "    train['x_max_over_y_min'] = train['x_max'] / train['y_min']\n",
    "    \n",
    "    train['slope'] = train['y_max_y_min'] / np.where(train['x_max_x_min']==0, 0.001, train['x_max_x_min'])\n",
    "    train['area'] = train['x_max_x_min'] * train['y_max_y_min']\n",
    "    \n",
    "    train['v_max_v_min'] = train['v_max'] - train['v_min']\n",
    "    \n",
    "    # mode_hour特征是指船号对应的出现频率最大的hour\n",
    "    mode_hour = df.groupby('ship')['hour'].agg(lambda x:x.value_counts().index[0]).to_dict()\n",
    "    # 用map将船号改为船号对应的mode_hour特征\n",
    "    train['mode_hour'] = train['ship'].map(mode_hour)\n",
    "    \n",
    "    # 提取hour和date的独特数量的特征\n",
    "    date_nunique = df.groupby('ship')['date'].nunique().to_dict()\n",
    "    train['date_nunique'] = train['ship'].map(date_nunique)\n",
    "    \n",
    "    # 提取时间差特征,时间数据的形式缩写为dt\n",
    "    t = df.groupby('ship')['time'].agg({'diff_time':lambda x:np.max(x)-np.min(x)}).reset_index()\n",
    "    t['diff_day'] = t['diff_time'].dt.days\n",
    "    t['diff_second'] = t['diff_time'].dt.seconds\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    return train\n",
    "\n",
    "# 时间特征处理\n",
    "def extract_dt(df):\n",
    "    df['time'] = pd.to_datetime(df['time'], format='%m%d %H:%M:%S')\n",
    "    df['date'] = df['time'].dt.date\n",
    "    df['hour'] = df['time'].dt.hour\n",
    "    df['weekday'] = df['time'].dt.weekday\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 做一些更复杂的交叉特征\n",
    "def get_interact_fea(df):\n",
    "    tr_train = df\n",
    "\n",
    "    tr_train['y_mad_over_x_mad'] = tr_train['y_mad'] / tr_train['x_mad']\n",
    "    tr_train['x_mad_over_y_mad'] = tr_train['x_mad'] / tr_train['y_mad']\n",
    "    \n",
    "    tr_train['x_over_y'] = tr_train['x'] / tr_train['y']\n",
    "    tr_train['y_over_x'] = tr_train['y'] / tr_train['x']\n",
    "    \n",
    "    tr_train['v_skew_v_std'] = tr_train['v_skew'] - tr_train['v_std']\n",
    "    tr_train['v_std_v_skew'] = tr_train['v_std'] - tr_train['v_skew']\n",
    "    tr_train['v_skew_over_v_std'] = tr_train['v_skew'] / tr_train['v_std']\n",
    "    tr_train['v_std_over_v_skew'] = tr_train['v_std'] / tr_train['v_skew']\n",
    "    \n",
    "    tr_train['y_skew_x_skew'] = tr_train['y_skew'] - tr_train['x_skew']\n",
    "    tr_train['x_skew_y_skew'] = tr_train['x_skew'] - tr_train['y_skew']\n",
    "    tr_train['y_skew_over_x_skew'] = tr_train['y_skew'] / tr_train['x_skew']\n",
    "    tr_train['x_skew_over_y_skew'] = tr_train['x_skew'] / tr_train['y_skew']\n",
    "\n",
    "    tr_train['y_me_x_me'] = tr_train['y_median'] - tr_train['x_median']\n",
    "    tr_train['x_me_y_me'] = tr_train['x_median'] - tr_train['y_median']\n",
    "    tr_train['y_me_over_x_me'] = tr_train['y_median'] / tr_train['x_median']\n",
    "    tr_train['x_me_over_y_me'] = tr_train['x_median'] / tr_train['y_median']\n",
    "    df = tr_train\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x_max': 'max', 'x_min': 'min', 'x_mean': 'mean', 'x_std': 'std', 'x_skew': 'skew', 'x_sum': 'sum', 'x_count': 'count', 'x_median': 'median', 'x_mad': 'mad'}\n",
      "{'y_max': 'max', 'y_min': 'min', 'y_mean': 'mean', 'y_std': 'std', 'y_skew': 'skew', 'y_sum': 'sum', 'y_median': 'median', 'y_mad': 'mad'}\n",
      "{'v_max': 'max', 'v_min': 'min', 'v_mean': 'mean', 'v_std': 'std', 'v_skew': 'skew', 'v_sum': 'sum', 'v_median': 'median', 'v_mad': 'mad'}\n",
      "{'d_max': 'max', 'd_min': 'min', 'd_mean': 'mean', 'd_std': 'std', 'd_skew': 'skew', 'd_sum': 'sum'}\n",
      "Features from 3482016 -> 3482016 -> 3482016 -> 3482016 -> 3482016 to 3482016\n"
     ]
    }
   ],
   "source": [
    "t1 = get_v_fea(data)\n",
    "t2 = get_x_fea(t1)\n",
    "t3 = extract_dt(t2)\n",
    "t4 = extract_feature(t3,t3)\n",
    "t5 = get_interact_fea(t4)\n",
    "a,b,c,d,e,f = [i.shape[1] for i in [data,t1,t2,t3,t4,t5]]\n",
    "print('Features from {} -> {} -> {} -> {} -> {} to {}'.format(a,b,c,d,e,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 速度分箱特征研究\n",
    "def get_bins(df,key,target,n):\n",
    "    tr = df\n",
    "    score_list = tr[tr[key]==n][target]\n",
    "    ma = np.ceil(max(score_list))\n",
    "    mi = np.floor(min(score_list))\n",
    "    bins = [mi] + [round((ma-mi)/i,2) for i in range(11,1,-1)] + [ma]\n",
    "    try:\n",
    "        score_cat = pd.cut(score_list,bins)\n",
    "        res = list(pd.value_counts(score_cat))\n",
    "        return [n,max(res)/sum(res)]\n",
    "    except ValueError:\n",
    "        return [n,0]\n",
    "\n",
    "# 速度加减变化的次数研究\n",
    "def get_v_change(df,key,target,n):\n",
    "    tr = df\n",
    "    p = tr[tr[key]==n][target]\n",
    "    i = j = k = 0\n",
    "    for v1,v2 in zip(p[:-1],p[1:]):\n",
    "        diff = v2 - v1\n",
    "        if diff > 0:\n",
    "            i += 1\n",
    "        elif diff == 0:\n",
    "            j += 1\n",
    "        else:\n",
    "            k += 1\n",
    "    return [n,i,j,k]\n",
    "\n",
    "# 速度加减变化的加速度研究\n",
    "def get_va_change(df,key,target,n):\n",
    "    tr = df\n",
    "    p = tr[tr[key]==n][target]\n",
    "    tt,t = [], []\n",
    "    for v1,v2 in zip(p[:-1],p[1:]):\n",
    "        diff = v2 - v1\n",
    "        t.append(diff)\n",
    "    va_sum,va_max,va_min = sum(t), max(t), min(t)\n",
    "    tt += [va_sum,va_max,va_min]\n",
    "    va_mean,va_median,va_std = np.mean(t),np.median(t),np.std(t)\n",
    "    tt += [va_mean,va_median,va_std]\n",
    "    va_skew = sp.stats.skew(t)\n",
    "    tt += [va_skew]\n",
    "    return [n] + tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 9000/9000 [03:34<00:00, 41.95it/s]\n"
     ]
    }
   ],
   "source": [
    "temp1,temp2,temp3 = [], [], []\n",
    "cols = ['ship','va_sum','va_max','va_min','va_mean','va_median','va_std','va_skew']\n",
    "\n",
    "for i in tqdm(range(9000)):\n",
    "    list1 = get_bins(data,'ship','v',i)\n",
    "    list2 = get_v_change(data,'ship','v',i)\n",
    "    list3 = get_va_change(data,'ship','v',i)\n",
    "    temp_df1 = pd.DataFrame([list1],columns=['ship','por_v'])\n",
    "    temp_df2 = pd.DataFrame([list2],columns=['ship','v_incre','v_keep','v_decre'])\n",
    "    temp_df3 = pd.DataFrame([list3],columns=cols)\n",
    "    temp1.append(temp_df1)\n",
    "    temp2.append(temp_df2)\n",
    "    temp3.append(temp_df3)\n",
    "    \n",
    "df1 = pd.concat(temp1)\n",
    "df2 = pd.concat(temp2)\n",
    "df3 = pd.concat(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ship     por_v\n",
      "0     0  0.577778\n",
      "0     1  0.464567\n",
      "0     2  0.977654\n",
      "0     3  0.611321\n",
      "0     4  0.729412 \n",
      "    ship  v_incre  v_keep  v_decre\n",
      "0     0       30     354       29\n",
      "0     1      140     106      138\n",
      "0     2       87      59       86\n",
      "0     3      122      89      123\n",
      "0     4      179      61      160 \n",
      "    ship  va_sum  va_max  va_min   va_mean  va_median    va_std   va_skew\n",
      "0     0   -2.59    6.80   -6.31 -0.006271        0.0  0.498274  0.802494\n",
      "0     1   -3.99    3.19   -4.58 -0.010391        0.0  0.640811 -1.459248\n",
      "0     2   -0.21   49.97  -50.46 -0.000905        0.0  4.839439 -0.139071\n",
      "0     3    1.35    8.58   -9.39  0.004042        0.0  1.613107 -0.212757\n",
      "0     4   -0.22    7.40   -9.39 -0.000550        0.0  2.028397 -0.354715\n",
      "\n",
      "\n",
      "(9000, 2) (9000, 4) (9000, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3482016, 94)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df1.head(),'\\n',df2.head(),'\\n',df3.head())\n",
    "print('\\n')\n",
    "print(df1.shape,df2.shape,df3.shape)\n",
    "\n",
    "new_data = t5\n",
    "new_data = pd.merge(new_data, df1, on='ship', how='left')\n",
    "new_data = pd.merge(new_data, df2, on='ship', how='left')\n",
    "new_data = pd.merge(new_data, df3, on='ship', how='left')\n",
    "\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'拖网': 0, '围网': 1, '刺网': 2}\n",
      "(9000, 94)\n"
     ]
    }
   ],
   "source": [
    "# 每艘船都有很多数据,针对不同(x,y,v,d)提取的特征都是单个值,所以需要去重操作\n",
    "data_label = new_data.drop_duplicates('ship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label.to_csv('bl4_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选出特征，准备训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [i for i in new_data.columns if i not in ['ship','type','time','diff_time','date']]\n",
    "target = 'type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_label[data_label['type']!=-1][feats].copy()\n",
    "y = data_label[data_label['type']!=-1][target]\n",
    "T = data_label[data_label['type']==-1][feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'拖网': 0, '围网': 1, '刺网': 2}\n",
      "(9000, 94)\n"
     ]
    }
   ],
   "source": [
    "# 将预测变量改为数值形式\n",
    "type_map = dict(zip(y.unique(),np.arange(3)))\n",
    "type_map_rev = {v:k for k,v in type_map.items()}\n",
    "y = y.map(type_map)\n",
    "\n",
    "print(type_map)\n",
    "print(data_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler1 = MinMaxScaler()\n",
    "scaler2 = StandardScaler()\n",
    "\n",
    "X1,T1 = X,T\n",
    "\n",
    "# X1.replace([np.inf,-np.inf],np.nan)\n",
    "# T1.replace([np.inf,-np.inf],np.nan)\n",
    "X1[np.isinf(X1)] = np.nan\n",
    "T1[np.isinf(T1)] = np.nan\n",
    "\n",
    "X1.fillna(0,inplace=True)\n",
    "T1.fillna(0,inplace=True)\n",
    "\n",
    "X1 = scaler1.fit_transform(X1)\n",
    "X2 = scaler2.fit_transform(X1)\n",
    "T1 = scaler1.fit_transform(T1)\n",
    "T2 = scaler2.fit_transform(T1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉验证训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意数据量只有7000行，10折或许会过对训练集拟合！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_oof_score(X,y,T,n_splits,verbose=100):\n",
    "    fold = StratifiedKFold(n_splits=n_splits,shuffle=True,random_state=42)\n",
    "    pred, oof = np.zeros((len(T),3)), np.zeros((len(X),3))\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': 5000,'boosting_type': 'gbdt','objective': 'multiclass',\n",
    "        'num_class': 3,'early_stopping_rounds': 200,\n",
    "    }\n",
    "\n",
    "    for index, (train_idx, val_idx) in enumerate(fold.split(X, y)):\n",
    "        train_set = lgb.Dataset(X.iloc[train_idx], y.iloc[train_idx])\n",
    "        val_set = lgb.Dataset(X.iloc[val_idx], y.iloc[val_idx])\n",
    "\n",
    "        model = lgb.train(params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbose)\n",
    "        val_pred = model.predict(X.iloc[val_idx])\n",
    "        oof[val_idx] = val_pred\n",
    "        val_y = y.iloc[val_idx]\n",
    "        val_pred = np.argmax(val_pred, axis=1)\n",
    "        score = metrics.f1_score(val_y, val_pred, average='macro')\n",
    "        print('Fold ',index+1 ,' Val F1-Score: ', round(score,5))\n",
    "\n",
    "        test_pred = model.predict(T)\n",
    "        pred += test_pred/n_splits\n",
    "\n",
    "    oof = np.argmax(oof, axis=1)\n",
    "    t_score = metrics.f1_score(oof, y, average='macro')\n",
    "    print('oof F1-Score',round(t_score,5),'\\n' )\n",
    "    print('Proportion of Prediction Label')\n",
    "    print(pd.DataFrame({'pred':np.argmax(pred,axis=1)})['pred'].value_counts(1))\n",
    "    return pred,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'拖网': 0, '围网': 1, '刺网': 2}\n",
      "0    0.623000\n",
      "1    0.231571\n",
      "2    0.145429\n",
      "Name: type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 对比训练集标签的比例\n",
    "print(type_map)\n",
    "print(y.value_counts(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0550215\tvalid_1's multi_logloss: 0.237831\n",
      "[200]\ttraining's multi_logloss: 0.0101541\tvalid_1's multi_logloss: 0.241664\n",
      "[300]\ttraining's multi_logloss: 0.0020164\tvalid_1's multi_logloss: 0.268311\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's multi_logloss: 0.0292724\tvalid_1's multi_logloss: 0.234268\n",
      "Fold  1  Val F1-Score:  0.88609\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0546533\tvalid_1's multi_logloss: 0.234812\n",
      "[200]\ttraining's multi_logloss: 0.0103901\tvalid_1's multi_logloss: 0.224471\n",
      "[300]\ttraining's multi_logloss: 0.00206653\tvalid_1's multi_logloss: 0.240765\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's multi_logloss: 0.0128151\tvalid_1's multi_logloss: 0.223033\n",
      "Fold  2  Val F1-Score:  0.89458\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0546749\tvalid_1's multi_logloss: 0.255426\n",
      "[200]\ttraining's multi_logloss: 0.0103033\tvalid_1's multi_logloss: 0.253981\n",
      "[300]\ttraining's multi_logloss: 0.00201991\tvalid_1's multi_logloss: 0.277985\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttraining's multi_logloss: 0.0164299\tvalid_1's multi_logloss: 0.250688\n",
      "Fold  3  Val F1-Score:  0.88517\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0556393\tvalid_1's multi_logloss: 0.232179\n",
      "[200]\ttraining's multi_logloss: 0.0106451\tvalid_1's multi_logloss: 0.226733\n",
      "[300]\ttraining's multi_logloss: 0.00211775\tvalid_1's multi_logloss: 0.245301\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's multi_logloss: 0.0239663\tvalid_1's multi_logloss: 0.223787\n",
      "Fold  4  Val F1-Score:  0.88355\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0529924\tvalid_1's multi_logloss: 0.240425\n",
      "[200]\ttraining's multi_logloss: 0.00974642\tvalid_1's multi_logloss: 0.242612\n",
      "[300]\ttraining's multi_logloss: 0.00187595\tvalid_1's multi_logloss: 0.267291\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttraining's multi_logloss: 0.0183599\tvalid_1's multi_logloss: 0.236883\n",
      "Fold  5  Val F1-Score:  0.87745\n",
      "oof F1-Score 0.88534 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.6365\n",
      "1    0.2315\n",
      "2    0.1320\n",
      "Name: pred, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pred, model = lgb_oof_score(X,y,T,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>x_per_1</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>y_max</td>\n",
       "      <td>335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>y_me_x_me</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>y_min</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>x_max_y_min</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>weekday</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hour</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>diff_day</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d_min</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>va_median</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  score\n",
       "64      x_per_1    348\n",
       "73        y_max    335\n",
       "79    y_me_x_me    315\n",
       "82        y_min    304\n",
       "57  x_max_y_min    295\n",
       "..          ...    ...\n",
       "48      weekday     13\n",
       "11         hour     10\n",
       "9      diff_day      7\n",
       "4         d_min      1\n",
       "43    va_median      0\n",
       "\n",
       "[89 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看特征重要性\n",
    "ret = []\n",
    "for index, model in enumerate([model]):\n",
    "    df = pd.DataFrame()\n",
    "    df['name'] = model.feature_name()\n",
    "    df['score'] = model.feature_importance()\n",
    "    df['fold'] = index\n",
    "    ret.append(df)\n",
    "    \n",
    "df = pd.concat(ret)\n",
    "df = df.groupby('name', as_index=False)['score'].mean()\n",
    "df = df.sort_values(['score'], ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征重选"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 手动选取重要性靠前的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_feas = list(df.name)\n",
    "good_feas = all_feas[:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0610283\tvalid_1's multi_logloss: 0.231908\n",
      "[200]\ttraining's multi_logloss: 0.0128107\tvalid_1's multi_logloss: 0.229281\n",
      "[300]\ttraining's multi_logloss: 0.00276735\tvalid_1's multi_logloss: 0.246715\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's multi_logloss: 0.0289301\tvalid_1's multi_logloss: 0.225003\n",
      "Fold  1  Val F1-Score:  0.89311\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0605514\tvalid_1's multi_logloss: 0.229683\n",
      "[200]\ttraining's multi_logloss: 0.0127828\tvalid_1's multi_logloss: 0.219484\n",
      "[300]\ttraining's multi_logloss: 0.00283041\tvalid_1's multi_logloss: 0.233977\n",
      "Early stopping, best iteration is:\n",
      "[181]\ttraining's multi_logloss: 0.0171628\tvalid_1's multi_logloss: 0.217532\n",
      "Fold  2  Val F1-Score:  0.89246\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0618003\tvalid_1's multi_logloss: 0.242186\n",
      "[200]\ttraining's multi_logloss: 0.0127088\tvalid_1's multi_logloss: 0.242015\n",
      "[300]\ttraining's multi_logloss: 0.00276551\tvalid_1's multi_logloss: 0.263526\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's multi_logloss: 0.0410375\tvalid_1's multi_logloss: 0.237443\n",
      "Fold  3  Val F1-Score:  0.87921\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.0627956\tvalid_1's multi_logloss: 0.233015\n",
      "[200]\ttraining's multi_logloss: 0.0133634\tvalid_1's multi_logloss: 0.220996\n",
      "[300]\ttraining's multi_logloss: 0.00300027\tvalid_1's multi_logloss: 0.233621\n",
      "Early stopping, best iteration is:\n",
      "[178]\ttraining's multi_logloss: 0.0187408\tvalid_1's multi_logloss: 0.218756\n",
      "Fold  4  Val F1-Score:  0.88694\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.05836\tvalid_1's multi_logloss: 0.244439\n",
      "[200]\ttraining's multi_logloss: 0.0118946\tvalid_1's multi_logloss: 0.241997\n",
      "[300]\ttraining's multi_logloss: 0.00258189\tvalid_1's multi_logloss: 0.265152\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttraining's multi_logloss: 0.0278647\tvalid_1's multi_logloss: 0.238229\n",
      "Fold  5  Val F1-Score:  0.87944\n",
      "oof F1-Score 0.88626 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.6325\n",
      "1    0.2395\n",
      "2    0.1280\n",
      "Name: pred, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1.41408635e-04, 9.99416104e-01, 4.42487782e-04],\n",
       "        [9.99516228e-01, 2.90891004e-04, 1.92881251e-04],\n",
       "        [3.94046693e-02, 9.57297155e-01, 3.29817565e-03],\n",
       "        ...,\n",
       "        [4.97882825e-03, 3.47923244e-01, 6.47097928e-01],\n",
       "        [9.98557392e-01, 8.04798595e-04, 6.37809095e-04],\n",
       "        [1.53383131e-02, 4.14102219e-01, 5.70559468e-01]]),\n",
       " <lightgbm.basic.Booster at 0x1e1636ce7b8>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_oof_score(X[good_feas],y,T[good_feas],5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA降维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99804785e-01, 1.94957232e-04, 2.57334479e-07, 1.04026280e-10,\n",
       "       3.16291421e-12])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=5)\n",
    "X_pca = pca.fit_transform(X)\n",
    "T_pca = pca.fit_transform(T)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1  Val F1-Score:  0.78814\n",
      "Fold  2  Val F1-Score:  0.76164\n",
      "Fold  3  Val F1-Score:  0.78811\n",
      "Fold  4  Val F1-Score:  0.78404\n",
      "Fold  5  Val F1-Score:  0.7735\n",
      "oof F1-Score 0.77915 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.5530\n",
      "2    0.2435\n",
      "1    0.2035\n",
      "Name: pred, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "_,_ = lgb_oof_score(pd.DataFrame(X_pca),y,pd.DataFrame(T_pca),5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1  Val F1-Score:  0.78814\n",
      "Fold  2  Val F1-Score:  0.76164\n",
      "Fold  3  Val F1-Score:  0.78811\n",
      "Fold  4  Val F1-Score:  0.78404\n",
      "Fold  5  Val F1-Score:  0.7735\n",
      "oof F1-Score 0.77915 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.5530\n",
      "2    0.2435\n",
      "1    0.2035\n",
      "Name: pred, dtype: float64\n",
      "Fold  1  Val F1-Score:  0.78278\n",
      "Fold  2  Val F1-Score:  0.75495\n",
      "Fold  3  Val F1-Score:  0.77759\n",
      "Fold  4  Val F1-Score:  0.80343\n",
      "Fold  5  Val F1-Score:  0.77105\n",
      "oof F1-Score 0.77817 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.6135\n",
      "1    0.1990\n",
      "2    0.1875\n",
      "Name: pred, dtype: float64\n",
      "Fold  1  Val F1-Score:  0.77356\n",
      "Fold  2  Val F1-Score:  0.75521\n",
      "Fold  3  Val F1-Score:  0.79022\n",
      "Fold  4  Val F1-Score:  0.80109\n",
      "Fold  5  Val F1-Score:  0.77389\n",
      "oof F1-Score 0.779 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.6905\n",
      "1    0.2065\n",
      "2    0.1030\n",
      "Name: pred, dtype: float64\n",
      "Fold  1  Val F1-Score:  0.77323\n",
      "Fold  2  Val F1-Score:  0.76751\n",
      "Fold  3  Val F1-Score:  0.78456\n",
      "Fold  4  Val F1-Score:  0.79938\n",
      "Fold  5  Val F1-Score:  0.7761\n",
      "oof F1-Score 0.78026 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.699\n",
      "1    0.227\n",
      "2    0.074\n",
      "Name: pred, dtype: float64\n",
      "Fold  1  Val F1-Score:  0.77833\n",
      "Fold  2  Val F1-Score:  0.76541\n",
      "Fold  3  Val F1-Score:  0.78287\n",
      "Fold  4  Val F1-Score:  0.79057\n",
      "Fold  5  Val F1-Score:  0.77161\n",
      "oof F1-Score 0.77784 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.7175\n",
      "1    0.2170\n",
      "2    0.0655\n",
      "Name: pred, dtype: float64\n",
      "Fold  1  Val F1-Score:  0.78225\n",
      "Fold  2  Val F1-Score:  0.76532\n",
      "Fold  3  Val F1-Score:  0.77599\n",
      "Fold  4  Val F1-Score:  0.7815\n",
      "Fold  5  Val F1-Score:  0.77718\n",
      "oof F1-Score 0.77651 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.6995\n",
      "1    0.2425\n",
      "2    0.0580\n",
      "Name: pred, dtype: float64\n",
      "Fold  1  Val F1-Score:  0.79486\n",
      "Fold  2  Val F1-Score:  0.76979\n",
      "Fold  3  Val F1-Score:  0.77144\n",
      "Fold  4  Val F1-Score:  0.78704\n",
      "Fold  5  Val F1-Score:  0.76566\n",
      "oof F1-Score 0.77777 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.70\n",
      "1    0.24\n",
      "2    0.06\n",
      "Name: pred, dtype: float64\n",
      "Fold  1  Val F1-Score:  0.77694\n",
      "Fold  2  Val F1-Score:  0.77405\n",
      "Fold  3  Val F1-Score:  0.78492\n",
      "Fold  4  Val F1-Score:  0.79395\n",
      "Fold  5  Val F1-Score:  0.77785\n",
      "oof F1-Score 0.78153 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.702\n",
      "1    0.232\n",
      "2    0.066\n",
      "Name: pred, dtype: float64\n",
      "Fold  1  Val F1-Score:  0.79551\n",
      "Fold  2  Val F1-Score:  0.75384\n",
      "Fold  3  Val F1-Score:  0.78256\n",
      "Fold  4  Val F1-Score:  0.79606\n",
      "Fold  5  Val F1-Score:  0.76923\n",
      "oof F1-Score 0.77965 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.7075\n",
      "1    0.2165\n",
      "2    0.0760\n",
      "Name: pred, dtype: float64\n",
      "Fold  1  Val F1-Score:  0.79233\n",
      "Fold  2  Val F1-Score:  0.77271\n",
      "Fold  3  Val F1-Score:  0.78454\n",
      "Fold  4  Val F1-Score:  0.78584\n",
      "Fold  5  Val F1-Score:  0.77564\n",
      "oof F1-Score 0.78239 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.7040\n",
      "1    0.2225\n",
      "2    0.0735\n",
      "Name: pred, dtype: float64\n",
      "Fold  1  Val F1-Score:  0.79209\n",
      "Fold  2  Val F1-Score:  0.77332\n",
      "Fold  3  Val F1-Score:  0.79187\n",
      "Fold  4  Val F1-Score:  0.7876\n",
      "Fold  5  Val F1-Score:  0.77469\n",
      "oof F1-Score 0.78401 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.7115\n",
      "1    0.2145\n",
      "2    0.0740\n",
      "Name: pred, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in range(5,16):\n",
    "    pca = PCA(n_components=i)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    T_pca = pca.fit_transform(T)  \n",
    "    _,_ = lgb_oof_score(pd.DataFrame(X_pca),y,pd.DataFrame(T_pca),5,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型对比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为一些模型的输入要归一化或标准化，所以先用lgb试一试normlized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "针对T1的预测值偏差太大，0类标签高达0.777，显然过拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1  Val F1-Score:  0.89141\n",
      "Fold  2  Val F1-Score:  0.88912\n",
      "Fold  3  Val F1-Score:  0.8832\n",
      "Fold  4  Val F1-Score:  0.88258\n",
      "Fold  5  Val F1-Score:  0.87515\n",
      "oof F1-Score 0.88423 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.777\n",
      "1    0.207\n",
      "2    0.016\n",
      "Name: pred, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[6.50800362e-04, 9.98200602e-01, 1.14859786e-03],\n",
       "        [9.98737635e-01, 8.67281186e-04, 3.95083640e-04],\n",
       "        [1.58283046e-01, 7.96367217e-01, 4.53497373e-02],\n",
       "        ...,\n",
       "        [8.69451159e-02, 7.47675733e-01, 1.65379152e-01],\n",
       "        [9.30889745e-01, 5.33091642e-02, 1.58010913e-02],\n",
       "        [4.86451764e-01, 2.95419458e-01, 2.18128778e-01]]),\n",
       " <lightgbm.basic.Booster at 0x1e1632655c0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_oof_score(pd.DataFrame(X1),y,pd.DataFrame(T1),5,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标准化的数据X2训练后用T2预测也得到过拟合的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1  Val F1-Score:  0.89541\n",
      "Fold  2  Val F1-Score:  0.87838\n",
      "Fold  3  Val F1-Score:  0.88144\n",
      "Fold  4  Val F1-Score:  0.88105\n",
      "Fold  5  Val F1-Score:  0.87523\n",
      "oof F1-Score 0.88228 \n",
      "\n",
      "Proportion of Prediction Label\n",
      "0    0.573\n",
      "1    0.296\n",
      "2    0.131\n",
      "Name: pred, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[2.92252615e-04, 9.98559896e-01, 1.14785153e-03],\n",
       "        [9.94863447e-01, 2.23298309e-03, 2.90356949e-03],\n",
       "        [3.46825127e-02, 9.60111875e-01, 5.20561244e-03],\n",
       "        ...,\n",
       "        [7.50721000e-03, 5.55302914e-01, 4.37189876e-01],\n",
       "        [9.85980376e-01, 9.21983504e-03, 4.79978849e-03],\n",
       "        [2.63574584e-02, 6.93902437e-01, 2.79740104e-01]]),\n",
       " <lightgbm.basic.Booster at 0x1e1636c2d68>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_oof_score(pd.DataFrame(X2),y,pd.DataFrame(T2),5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_score(Model,X,y,T,n_split):\n",
    "    fold = StratifiedKFold(n_splits=n_split,shuffle=True,random_state=42)\n",
    "    models = []\n",
    "    pred = np.zeros((len(T),3))\n",
    "    oof = np.zeros((len(X),1))\n",
    "\n",
    "    for index, (train_idx, val_idx) in enumerate(fold.split(X, y)):\n",
    "        train_x = X.iloc[train_idx]\n",
    "        train_y = y.iloc[train_idx]\n",
    "        val_x = X.iloc[val_idx]\n",
    "        val_y = y.iloc[val_idx]\n",
    "        if type(Model) == CatBoostClassifier:\n",
    "            model = Model.fit(train_x,train_y,silent=True)\n",
    "        else:\n",
    "            model = Model.fit(train_x,train_y)\n",
    "        models.append(model)\n",
    "        p = val_pred = model.predict(X.iloc[val_idx])\n",
    "        oof[val_idx] = val_pred.reshape(-1,1)\n",
    "        val_y = y.iloc[val_idx]\n",
    "        \n",
    "        print(index+1, 'Val F1-Score', metrics.f1_score(val_y, val_pred, average='macro'))\n",
    "\n",
    "        test_proba = model.predict_proba(T)\n",
    "        pred += test_proba/n_split\n",
    "    print('oof f1', metrics.f1_score(oof, y, average='macro'))\n",
    "    return np.argmax(pred,axis=1),model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression()\n",
    "clf2 = svm.SVC()\n",
    "clf3 = GaussianNB()\n",
    "clf4 = KNeighborsClassifier()\n",
    "clf5 = RandomForestClassifier()\n",
    "clf6 = AdaBoostClassifier()\n",
    "clf7 = GradientBoostingClassifier()\n",
    "clf8 = XGBClassifier()\n",
    "clf9 = LGBMClassifier()\n",
    "clf10 = CatBoostClassifier()\n",
    "clf11 = ExtraTreesClassifier()\n",
    "\n",
    "clfs = [clf1,clf2,clf3,clf4,clf5,clf6,clf7,clf8,clf9,clf10,clf11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "1 Val F1-Score 0.6398210420056181\n",
      "2 Val F1-Score 0.6441856360771774\n",
      "3 Val F1-Score 0.6236970420775785\n",
      "4 Val F1-Score 0.6297478310078696\n",
      "5 Val F1-Score 0.6160391891837704\n",
      "oof f1 0.6311750471744221\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "\n",
      "\n",
      "<class 'sklearn.svm.classes.SVC'>\n",
      "1 Val F1-Score 0.6888400538615457\n",
      "2 Val F1-Score 0.6995513124562258\n",
      "3 Val F1-Score 0.6983390667829065\n",
      "4 Val F1-Score 0.694829578653509\n",
      "5 Val F1-Score 0.6856762573411775\n",
      "oof f1 0.6935640568701166\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "\n",
      "\n",
      "<class 'sklearn.naive_bayes.GaussianNB'>\n",
      "1 Val F1-Score 0.5595013219952458\n",
      "2 Val F1-Score 0.5726557234730362\n",
      "3 Val F1-Score 0.5398686958595917\n",
      "4 Val F1-Score 0.543938957185248\n",
      "5 Val F1-Score 0.5709789018872683\n",
      "oof f1 0.5575281496116499\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "\n",
      "\n",
      "<class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "1 Val F1-Score 0.6934039314072336\n",
      "2 Val F1-Score 0.7023277726611409\n",
      "3 Val F1-Score 0.7288089801841249\n",
      "4 Val F1-Score 0.6785900464983209\n",
      "5 Val F1-Score 0.6733469481229427\n",
      "oof f1 0.6953673992092058\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "1 Val F1-Score 0.8563249289754085\n",
      "2 Val F1-Score 0.838960409867901\n",
      "3 Val F1-Score 0.8642155698936745\n",
      "4 Val F1-Score 0.8502581257573834\n",
      "5 Val F1-Score 0.8355279575477462\n",
      "oof f1 0.8490854729939049\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>\n",
      "1 Val F1-Score 0.7268824286094023\n",
      "2 Val F1-Score 0.7420126979493542\n",
      "3 Val F1-Score 0.7328397120438209\n",
      "4 Val F1-Score 0.7059507542266162\n",
      "5 Val F1-Score 0.7107736821299294\n",
      "oof f1 0.7234241392739817\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "1 Val F1-Score 0.8463687027828385\n",
      "2 Val F1-Score 0.8411508205214625\n",
      "3 Val F1-Score 0.830832616292342\n",
      "4 Val F1-Score 0.8377720786972875\n",
      "5 Val F1-Score 0.8222426909452247\n",
      "oof f1 0.8357986454387317\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "\n",
      "\n",
      "<class 'xgboost.sklearn.XGBClassifier'>\n",
      "1 Val F1-Score 0.8301662585260713\n",
      "2 Val F1-Score 0.8225001313115397\n",
      "3 Val F1-Score 0.8262769129264448\n",
      "4 Val F1-Score 0.8015057973496122\n",
      "5 Val F1-Score 0.8041683872248374\n",
      "oof f1 0.8168129060861792\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "\n",
      "\n",
      "<class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "1 Val F1-Score 0.8888230933185062\n",
      "2 Val F1-Score 0.8669360889950396\n",
      "3 Val F1-Score 0.8744314214691009\n",
      "4 Val F1-Score 0.8783840795350516\n",
      "5 Val F1-Score 0.8707306506974927\n",
      "oof f1 0.8758456831008478\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "\n",
      "\n",
      "<class 'catboost.core.CatBoostClassifier'>\n",
      "1 Val F1-Score 0.8471383109071945\n",
      "2 Val F1-Score 0.8440294582466533\n",
      "3 Val F1-Score 0.8519902402219556\n",
      "4 Val F1-Score 0.8402108224612442\n",
      "5 Val F1-Score 0.8394645646862671\n",
      "oof f1 0.8445204346241821\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "\n",
      "\n",
      "<class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n",
      "1 Val F1-Score 0.8485031246381985\n",
      "2 Val F1-Score 0.8514809741132497\n",
      "3 Val F1-Score 0.8631151956421327\n",
      "4 Val F1-Score 0.8466569279977504\n",
      "5 Val F1-Score 0.8468442236707645\n",
      "oof f1 0.8513151789065928\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for clf in clfs:\n",
    "    print(type(clf))\n",
    "    _,_ = get_model_score(clf,pd.DataFrame(X2),y,pd.DataFrame(T2),5)\n",
    "    print('-*-'*30)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对表现较好的模型进行简单调参"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "极端随机树展现出惊人的实力！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Val F1-Score 0.9007356871434542\n",
      "2 Val F1-Score 0.8899338549139572\n",
      "3 Val F1-Score 0.9017125988572889\n",
      "4 Val F1-Score 0.8899536174269292\n",
      "5 Val F1-Score 0.8857607540369178\n",
      "oof f1 0.893604078161521\n",
      "0    0.6405\n",
      "1    0.2385\n",
      "2    0.1210\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "new_clf11 = ExtraTreesClassifier(n_estimators=800)\n",
    "pred,_ = get_model_score(new_clf11,X[good_feas],y,T[good_feas],5)\n",
    "print(pd.DataFrame(pred)[0].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机森林也不错！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Val F1-Score 0.893772634787218\n",
      "2 Val F1-Score 0.8950270431940347\n",
      "3 Val F1-Score 0.8936606817935931\n",
      "4 Val F1-Score 0.8898857931040767\n",
      "5 Val F1-Score 0.8681637187607357\n",
      "oof f1 0.8880473073375735\n",
      "0    0.6405\n",
      "1    0.2375\n",
      "2    0.1220\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "new_clf5 = RandomForestClassifier(n_estimators=800)\n",
    "pred,_ = get_model_score(new_clf5,X[good_feas],y,T[good_feas],5)\n",
    "print(pd.DataFrame(pred)[0].value_counts(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators':500,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 10,\n",
    "    'random_state':42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB有点失望,速度慢,分数也不高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Val F1-Score 0.8914344019577346\n",
      "2 Val F1-Score 0.8875030261498814\n",
      "3 Val F1-Score 0.8828054858982693\n",
      "4 Val F1-Score 0.8856627669381975\n",
      "5 Val F1-Score 0.8759302123254148\n",
      "oof f1 0.8846495722541001\n",
      "0    0.639\n",
      "1    0.242\n",
      "2    0.119\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "new_clf8 = XGBClassifier(**params)\n",
    "pred,_ = get_model_score(new_clf8,X[good_feas],y,T[good_feas],5)\n",
    "print(pd.DataFrame(pred)[0].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAT效果一般，速度太慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'iterations':500,\n",
    "    'learning_rate': 0.01,\n",
    "    'depth': 10,\n",
    "    'random_state':42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Val F1-Score 0.7901082583518124\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-6c301713fc1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnew_clf10\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_clf10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgood_feas\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgood_feas\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-130-a324eecbdf48>\u001b[0m in \u001b[0;36mget_model_score\u001b[1;34m(Model, X, y, T, n_split)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mval_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, cat_features, text_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   3791\u001b[0m         self._fit(X, y, cat_features, text_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0;32m   3792\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3793\u001b[1;33m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\n\u001b[0m\u001b[0;32m   3794\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, cat_features, text_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model)\u001b[0m\n\u001b[0;32m   1688\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1690\u001b[1;33m                 \u001b[0mtrain_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"init_model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1691\u001b[0m             )\n\u001b[0;32m   1692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36m_train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1225\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1226\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "new_clf10 = CatBoostClassifier(**params)\n",
    "pred,_ = get_model_score(new_clf10,X[good_feas],y,T[good_feas],5)\n",
    "print(pd.DataFrame(pred)[0].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators':500,\n",
    "    'learning_rate': 0.01,\n",
    "    'random_state':42,\n",
    "    'silent':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Val F1-Score 0.8737584738357386\n",
      "2 Val F1-Score 0.8649272415130641\n",
      "3 Val F1-Score 0.8707301768206724\n",
      "4 Val F1-Score 0.8739250445906485\n",
      "5 Val F1-Score 0.8574317988112056\n",
      "oof f1 0.8681745934137491\n",
      "0    0.6315\n",
      "1    0.2430\n",
      "2    0.1255\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "new_clf9 = LGBMClassifier(**params)\n",
    "pred,_ = get_model_score(new_clf9,X[good_feas],y,T[good_feas],5)\n",
    "print(pd.DataFrame(pred)[0].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking(Models,X,y,T,feats,n_split):\n",
    "    X = X[feats]\n",
    "    New_features = np.zeros((X.shape[0],len(Models)))\n",
    "    New_test = np.zeros((T.shape[0],len(Models)))\n",
    "    \n",
    "    for i,clf in enumerate(Models):\n",
    "        # 第i个模型对测试集的预测\n",
    "        New_test_i = np.zeros((T.shape[0],3))\n",
    "        # 第i个模型对训练集的预测概率\n",
    "        New_features_i = np.zeros((X.shape[0],3))\n",
    "        \n",
    "        pred = np.zeros((len(T),1))\n",
    "        oof = np.zeros((len(X),1))\n",
    "        \n",
    "        fold = StratifiedKFold(n_splits=n_split,shuffle=True,random_state=42)\n",
    "        models = []\n",
    "        \n",
    "        for j, (train_idx, val_idx) in enumerate(fold.split(X, y)):\n",
    "            train_x = X.iloc[train_idx]\n",
    "            train_y = y.iloc[train_idx]\n",
    "            val_x = X.iloc[val_idx]\n",
    "            val_y = y.iloc[val_idx]\n",
    "            if type(clf) == CatBoostClassifier:\n",
    "                clf.fit(train_x,train_y,silent=True)\n",
    "            else:\n",
    "                clf.fit(train_x,train_y)\n",
    "            models.append(clf)\n",
    "            val_pred = clf.predict(X.iloc[val_idx])\n",
    "            oof[val_idx] = val_pred.reshape(-1,1)\n",
    "            val_y = y.iloc[val_idx]\n",
    "            score = metrics.f1_score(val_y, val_pred, average='macro')\n",
    "            print('Model {} in {} Fold Val F1-Score:'.format(i+1,j),round(score,5))\n",
    "\n",
    "            val_pred_prob = clf.predict_proba(X.iloc[val_idx])\n",
    "            New_features_i[val_idx] = val_pred_prob\n",
    "            \n",
    "            # 第i个模型在第j折的情况下对全部测试集的预测\n",
    "            test_prob = clf.predict_proba(T[feats])\n",
    "            New_test_i += test_prob/n_split\n",
    "        t_score = metrics.f1_score(oof, y, average='macro')\n",
    "        print('Model {} oof F1-Score:'.format(i+1),round(t_score,5) )\n",
    "        \n",
    "    # 简单算数融合训练集预测值作为新特征\n",
    "    New_features += New_features_i/len(Models)\n",
    "    New_test += New_test_i/len(Models)\n",
    "    # 输出第一层模型得到的新特征，新测试集，以及训练好的模型\n",
    "    return New_features,New_test,models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一层：clf5-RF,clf8-XGB,clf11-ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 in 0 Fold Val F1-Score: 0.89365\n",
      "Model 1 in 1 Fold Val F1-Score: 0.89599\n",
      "Model 1 in 2 Fold Val F1-Score: 0.8948\n",
      "Model 1 in 3 Fold Val F1-Score: 0.88789\n",
      "Model 1 in 4 Fold Val F1-Score: 0.86771\n",
      "Model 1 oof F1-Score: 0.88797\n",
      "Model 2 in 0 Fold Val F1-Score: 0.89143\n",
      "Model 2 in 1 Fold Val F1-Score: 0.8875\n",
      "Model 2 in 2 Fold Val F1-Score: 0.88281\n",
      "Model 2 in 3 Fold Val F1-Score: 0.88566\n",
      "Model 2 in 4 Fold Val F1-Score: 0.87593\n",
      "Model 2 oof F1-Score: 0.88465\n",
      "Model 3 in 0 Fold Val F1-Score: 0.89886\n",
      "Model 3 in 1 Fold Val F1-Score: 0.8867\n",
      "Model 3 in 2 Fold Val F1-Score: 0.90107\n",
      "Model 3 in 3 Fold Val F1-Score: 0.8891\n",
      "Model 3 in 4 Fold Val F1-Score: 0.88436\n",
      "Model 3 oof F1-Score: 0.89201\n"
     ]
    }
   ],
   "source": [
    "M1 = [new_clf5,new_clf8,new_clf11]\n",
    "X_2,T_2,M1_models = Stacking(M1,X,y,T,good_fea[:45],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 3) (2000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_2.shape,T_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二层：lgb or ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[300]\ttraining's multi_logloss: 0.0020164\tvalid_1's multi_logloss: 0.268311\n",
      "[600]\ttraining's multi_logloss: 1.65539e-05\tvalid_1's multi_logloss: 0.384211\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's multi_logloss: 0.0292724\tvalid_1's multi_logloss: 0.234268\n",
      "0 val f1 0.8860908934907261\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[300]\ttraining's multi_logloss: 0.00206653\tvalid_1's multi_logloss: 0.240765\n",
      "[600]\ttraining's multi_logloss: 1.72e-05\tvalid_1's multi_logloss: 0.324521\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's multi_logloss: 0.0128151\tvalid_1's multi_logloss: 0.223033\n",
      "1 val f1 0.8945801905665299\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[300]\ttraining's multi_logloss: 0.00201991\tvalid_1's multi_logloss: 0.277985\n",
      "[600]\ttraining's multi_logloss: 1.67566e-05\tvalid_1's multi_logloss: 0.38493\n",
      "Early stopping, best iteration is:\n",
      "[171]\ttraining's multi_logloss: 0.0164299\tvalid_1's multi_logloss: 0.250688\n",
      "2 val f1 0.8851735757209434\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[300]\ttraining's multi_logloss: 0.00211775\tvalid_1's multi_logloss: 0.245301\n",
      "[600]\ttraining's multi_logloss: 1.83388e-05\tvalid_1's multi_logloss: 0.336951\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's multi_logloss: 0.0239663\tvalid_1's multi_logloss: 0.223787\n",
      "3 val f1 0.8835466166011354\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[300]\ttraining's multi_logloss: 0.00187595\tvalid_1's multi_logloss: 0.267291\n",
      "[600]\ttraining's multi_logloss: 1.49796e-05\tvalid_1's multi_logloss: 0.364289\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttraining's multi_logloss: 0.0183599\tvalid_1's multi_logloss: 0.236883\n",
      "4 val f1 0.8774523675638597\n",
      "oof f1 0.8853440705988559\n"
     ]
    }
   ],
   "source": [
    "fold = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "pred = np.zeros((len(T),3))\n",
    "oof = np.zeros((len(X),3))\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 5000,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'early_stopping_rounds': 500,\n",
    "}\n",
    "\n",
    "for index, (train_idx, val_idx) in enumerate(fold.split(X_2, y)):\n",
    "\n",
    "    train_set = lgb.Dataset(X.iloc[train_idx], y.iloc[train_idx])\n",
    "    val_set = lgb.Dataset(X.iloc[val_idx], y.iloc[val_idx])\n",
    "\n",
    "    model = lgb.train(params, train_set, valid_sets=[train_set, val_set], verbose_eval=300)\n",
    "    val_pred = model.predict(X.iloc[val_idx])\n",
    "    oof[val_idx] = val_pred\n",
    "    val_y = y.iloc[val_idx]\n",
    "    val_pred = np.argmax(val_pred, axis=1)\n",
    "    print(index, 'val f1', metrics.f1_score(val_y, val_pred, average='macro'))\n",
    "\n",
    "    test_pred = model.predict(T_2)\n",
    "    pred += test_pred/5\n",
    "\n",
    "oof = np.argmax(oof, axis=1)\n",
    "print('oof f1', metrics.f1_score(oof, y, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Val F1-Score 0.8910725913440749\n",
      "2 Val F1-Score 0.871716676763367\n",
      "3 Val F1-Score 0.8855261987123426\n",
      "4 Val F1-Score 0.8676795395466496\n",
      "5 Val F1-Score 0.8572779032290363\n",
      "oof f1 0.8746172085703309\n",
      "0    0.6315\n",
      "1    0.2285\n",
      "2    0.1400\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "Final_clf11 = ExtraTreesClassifier(n_estimators=800)\n",
    "pred,_ = get_model_score(Final_clf11,pd.DataFrame(X_2),y,pd.DataFrame(T_2),5)\n",
    "print(pd.DataFrame(pred)[0].value_counts(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在LGB和ET分别作为第二层模型的情况下，效果都不如单个模型表现好，尝试使用所用的模型做第二层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression()\n",
    "clf2 = svm.SVC(probability=True)\n",
    "clf3 = GaussianNB()\n",
    "clf4 = KNeighborsClassifier()\n",
    "clf5 = RandomForestClassifier(n_estimators=818)\n",
    "clf6 = AdaBoostClassifier()\n",
    "clf7 = GradientBoostingClassifier()\n",
    "clf8 = XGBClassifier()\n",
    "clf9 = LGBMClassifier()\n",
    "clf10 = CatBoostClassifier()\n",
    "clf11 = ExtraTreesClassifier(n_estimators=818)\n",
    "\n",
    "clfs = [clf1,clf2,clf3,clf4,clf5,clf6,clf7,clf8,clf9,clf10,clf11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  1 <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "1 Val F1-Score 0.8992799715388822\n",
      "2 Val F1-Score 0.8879686115323421\n",
      "3 Val F1-Score 0.9007923484039239\n",
      "4 Val F1-Score 0.8908328440197274\n",
      "5 Val F1-Score 0.8832457152314848\n",
      "oof f1 0.8924028053963067\n",
      "0    0.648\n",
      "1    0.233\n",
      "2    0.119\n",
      "Name: 0, dtype: float64\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Model  2 <class 'sklearn.svm.classes.SVC'>\n",
      "1 Val F1-Score 0.8937041758535003\n",
      "2 Val F1-Score 0.8926043706210587\n",
      "3 Val F1-Score 0.9070373903957112\n",
      "4 Val F1-Score 0.8895557881905288\n",
      "5 Val F1-Score 0.8899510806756107\n",
      "oof f1 0.8945451587072305\n",
      "0    0.6325\n",
      "1    0.2330\n",
      "2    0.1345\n",
      "Name: 0, dtype: float64\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Model  3 <class 'sklearn.naive_bayes.GaussianNB'>\n",
      "1 Val F1-Score 0.8897350764807016\n",
      "2 Val F1-Score 0.9007955992272758\n",
      "3 Val F1-Score 0.9060219912056936\n",
      "4 Val F1-Score 0.8850131270506068\n",
      "5 Val F1-Score 0.8853284263033787\n",
      "oof f1 0.893326750276697\n",
      "0    0.6035\n",
      "1    0.2525\n",
      "2    0.1440\n",
      "Name: 0, dtype: float64\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Model  4 <class 'sklearn.neighbors.classification.KNeighborsClassifier'>\n",
      "1 Val F1-Score 0.896240329732677\n",
      "2 Val F1-Score 0.8865041057271551\n",
      "3 Val F1-Score 0.8918849491519474\n",
      "4 Val F1-Score 0.8813626040184289\n",
      "5 Val F1-Score 0.8648924520581414\n",
      "oof f1 0.8840918489822872\n",
      "0    0.6355\n",
      "1    0.2255\n",
      "2    0.1390\n",
      "Name: 0, dtype: float64\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Model  5 <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "1 Val F1-Score 0.8898450943209207\n",
      "2 Val F1-Score 0.8812585241897816\n",
      "3 Val F1-Score 0.8895763232119935\n",
      "4 Val F1-Score 0.8656633795959036\n",
      "5 Val F1-Score 0.8646032643010306\n",
      "oof f1 0.8781692016705579\n",
      "0    0.6320\n",
      "1    0.2285\n",
      "2    0.1395\n",
      "Name: 0, dtype: float64\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Model  6 <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>\n",
      "1 Val F1-Score 0.8893097382693466\n",
      "2 Val F1-Score 0.8941553790945522\n",
      "3 Val F1-Score 0.8980793062689871\n",
      "4 Val F1-Score 0.8845742528296595\n",
      "5 Val F1-Score 0.8640706010535059\n",
      "oof f1 0.8860772897451524\n",
      "0    0.6185\n",
      "1    0.2315\n",
      "2    0.1500\n",
      "Name: 0, dtype: float64\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Model  7 <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>\n",
      "1 Val F1-Score 0.8928524524292291\n",
      "2 Val F1-Score 0.88266188977903\n",
      "3 Val F1-Score 0.8981954638099715\n",
      "4 Val F1-Score 0.8907162835651681\n",
      "5 Val F1-Score 0.8790693930718091\n",
      "oof f1 0.8886838994168939\n",
      "0    0.6355\n",
      "1    0.2265\n",
      "2    0.1380\n",
      "Name: 0, dtype: float64\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Model  8 <class 'xgboost.sklearn.XGBClassifier'>\n",
      "1 Val F1-Score 0.898253384429812\n",
      "2 Val F1-Score 0.8869577925385622\n",
      "3 Val F1-Score 0.9013700637636916\n",
      "4 Val F1-Score 0.8947624223150878\n",
      "5 Val F1-Score 0.8834709165689923\n",
      "oof f1 0.8929642179899228\n",
      "0    0.6340\n",
      "1    0.2285\n",
      "2    0.1375\n",
      "Name: 0, dtype: float64\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n",
      "Model  10 <class 'catboost.core.CatBoostClassifier'>\n",
      "1 Val F1-Score 0.898811257432009\n",
      "2 Val F1-Score 0.8907441646370816\n",
      "3 Val F1-Score 0.9015377917102055\n",
      "4 Val F1-Score 0.8833572915668716\n",
      "5 Val F1-Score 0.881982427218882\n",
      "oof f1 0.8912636827047512\n",
      "0    0.6335\n",
      "1    0.2305\n",
      "2    0.1360\n",
      "Name: 0, dtype: float64\n",
      "-*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*--*-\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "i = 0\n",
    "for clf in clfs:\n",
    "    i += 1\n",
    "    if clf == clf9 or clf == clf11:\n",
    "        continue\n",
    "    print('Model ',i,type(clf))\n",
    "    pred,_ = get_model_score(clf,pd.DataFrame(X_2),y,pd.DataFrame(T_2),5)\n",
    "    result.append(pred)\n",
    "    print(pd.DataFrame(pred)[0].value_counts(1))\n",
    "    print('-*-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在胡乱实验的情况下发现SVM竟然可以进一步提升效果！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = data_label[data_label['type']==-1][['ship']]\n",
    "sub['pred'] = result[1]\n",
    "sub['pred'] = sub['pred'].map(type_map_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "拖网    0.6325\n",
       "围网    0.2330\n",
       "刺网    0.1345\n",
       "Name: pred, dtype: float64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['pred'].value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./output/bs4_stacking_89454.csv',index=False,header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
